{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"classification_mnist.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"em45VNO8D-Om","colab_type":"text"},"cell_type":"markdown","source":["# Part II: Convolutional Neural Networks\n","\n","## Workshop em Deep Learning\n","\n","\n","```\n","\t\n","\t@author: Rafa Felix <rafael.felixalves@adelaide.edu.au>\n","\tAustralian Centre for Robotic Vision (ACRV)\n","\tSchool of Computer Science\n","\tThe University of Adelaide\n","\t\n","\tReferences:\n","  [1]\n","\t\n","\n","```\n","\n","---\n","\n","### Instituto Federal de Minas Gerais\n"]},{"metadata":{"id":"3Lk6dbYKUTe4","colab_type":"text"},"cell_type":"markdown","source":["# Verificando versão do Python"]},{"metadata":{"id":"uyru9N2mUTvS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"0b0463ab-6de3-4664-8bd7-874d7763f4a2","executionInfo":{"status":"ok","timestamp":1532122009792,"user_tz":-570,"elapsed":1760,"user":{"displayName":"Rafa Félix","photoUrl":"//lh4.googleusercontent.com/-rJxKyqW78NY/AAAAAAAAAAI/AAAAAAAAAIA/T-S-BEUsMmc/s50-c-k-no/photo.jpg","userId":"108986600904287319000"}}},"cell_type":"code","source":["import sys\n","sys.version"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'3.6.3 (default, Oct  3 2017, 21:45:48) \\n[GCC 7.2.0]'"]},"metadata":{"tags":[]},"execution_count":1}]},{"metadata":{"id":"DOsxPYydScXy","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":391},"outputId":"9d961da8-fc4f-4e0b-8ea2-0de31ed9b557","executionInfo":{"status":"ok","timestamp":1532122062060,"user_tz":-570,"elapsed":49060,"user":{"displayName":"Rafa Félix","photoUrl":"//lh4.googleusercontent.com/-rJxKyqW78NY/AAAAAAAAAAI/AAAAAAAAAIA/T-S-BEUsMmc/s50-c-k-no/photo.jpg","userId":"108986600904287319000"}}},"cell_type":"code","source":["# pip3: assistente de pacotes do python 3.\n","# pytorch: framework para desenvolvimento de algoritmos Deep Learning;\n","\n","# instalação do pytorch\n","!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n","\n","#torchvision: framework do pytorch com banco de dados e modelos de deep learning\n","#             que já são considerados estáveis pela comunidade científica.\n","\n","# instalação do torchvision\n","!pip3 install torchvision\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting torch==0.3.0.post4 from http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n","\u001b[?25l  Downloading http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl (592.3MB)\n","\u001b[K    95% |██████████████████████████████▋ | 565.8MB 52.4MB/s eta 0:00:01"],"name":"stdout"},{"output_type":"stream","text":["\u001b[K    100% |████████████████████████████████| 592.3MB 48.6MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (3.13)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (1.14.5)\n","Installing collected packages: torch\n","Successfully installed torch-0.3.0.post4\n","Collecting torchvision\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n","\u001b[K    100% |████████████████████████████████| 61kB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.3.0.post4)\n","Collecting pillow>=4.1.1 (from torchvision)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/24/f53ff6b61b3d728b90934bddb4f03f8ab584a7f49299bf3bde56e2952612/Pillow-5.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n","\u001b[K    100% |████████████████████████████████| 2.0MB 7.1MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch->torchvision) (3.13)\n","Installing collected packages: pillow, torchvision\n","  Found existing installation: Pillow 4.0.0\n","    Uninstalling Pillow-4.0.0:\n","      Successfully uninstalled Pillow-4.0.0\n","Successfully installed pillow-5.2.0 torchvision-0.2.1\n"],"name":"stdout"}]},{"metadata":{"id":"YFgOPtFAUfMU","colab_type":"text"},"cell_type":"markdown","source":["# Importando e verificando Pytorch e TorchVision"]},{"metadata":{"id":"3lJlxrS9SsvR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import torch #importando torch\n","import torch.nn as nn # importando pacote de neural networks nn\n","\n","# importando pacote de datasets, a este atribuimos o alias dsets\n","import torchvision.datasets as dsets \n","\n","# importando pacote de data augmentation\n","import torchvision.transforms as transforms \n","\n","# importando pacote de grafos e gradientes\n","from torch.autograd import Variable"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L9b_xEGtszgx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# importando pacote time\n","import time\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kkm_s0X7VOex","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["input_size    = 784   # The image size = 28 x 28 = 784\n","num_classes   = 10    # The number of output classes. In this case, from 0 to 9\n","num_epochs    = 5     # The number of times entire dataset is trained\n","batch_size    = 100   # The size of input data took for one iteration\n","learning_rate = 1e-3  # The speed of convergence\n","\n","# use_cuda é um parametro que utilizamos em nosso código para\n","# definir onde utilizaremos a GPU ou não. Como estamos utilizando o Google Colab\n","# podemos utilizar use_cuda como True. Caso você tente executar em uma outra\n","# plataforma que não possua GPU, utilize está flag como False.\n","use_cuda = True"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gRxhPDg1FDpF","colab_type":"text"},"cell_type":"markdown","source":["# Dataset"]},{"metadata":{"id":"ixvmEcQsVSZh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":119},"outputId":"eed26ba3-3336-4028-9a73-1dd19c94e3b9","executionInfo":{"status":"ok","timestamp":1532122179601,"user_tz":-570,"elapsed":2753,"user":{"displayName":"Rafa Félix","photoUrl":"//lh4.googleusercontent.com/-rJxKyqW78NY/AAAAAAAAAAI/AAAAAAAAAIA/T-S-BEUsMmc/s50-c-k-no/photo.jpg","userId":"108986600904287319000"}}},"cell_type":"code","source":["# dsets é o alias que atribuimos ao pacote torchvision.datasets\n","\n","# MNIST consiste em um dataset de caracteres.\n","# Normalmente o MNIST é o dataset mais utilizado educacionalmente\n","# em visão computacional;\n","train_dataset = dsets.MNIST(root='./data',\n","                           train=True,\n","                           transform=transforms.ToTensor(),\n","                           download=True)\n","\n","test_dataset = dsets.MNIST(root='./data',\n","                           train=False,\n","                           transform=transforms.ToTensor())"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Processing...\n","Done!\n"],"name":"stdout"}]},{"metadata":{"id":"0YHZdQ09WVe3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n","# Para treino, utilizamos a função shuffle = true\n","# Utilizamos a função shuffle para evitar overfitting\n","# e adicionar estocasticidade ao processo.\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=True)\n","\n","# Para test, utilizamos a função shuffle = false\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tgTwUNcEHsQr","colab_type":"text"},"cell_type":"markdown","source":["## Visualizando exemplares do MNIST\n","\n"]},{"metadata":{"id":"alslkXcRFvVa","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":314},"outputId":"44f75945-e0a4-45d0-ba9a-cab55a2ca942","executionInfo":{"status":"ok","timestamp":1532122205788,"user_tz":-570,"elapsed":2048,"user":{"displayName":"Rafa Félix","photoUrl":"//lh4.googleusercontent.com/-rJxKyqW78NY/AAAAAAAAAAI/AAAAAAAAAIA/T-S-BEUsMmc/s50-c-k-no/photo.jpg","userId":"108986600904287319000"}}},"cell_type":"code","source":["# Informacoes do dataset\n","\n","# dimensoes\n","print(train_loader.dataset.train_data.size())                 # (60000, 28, 28)\n","\n","# classes\n","print(train_loader.dataset.train_labels.size())               # (60000)\n","\n","# plotting digito\n","plt.imshow(train_loader.dataset.train_data[0].numpy(),  # mudar o numero dentro para exibir outros exemplares\n","           cmap='gray')\n","plt.title('%i' % train_loader.dataset.train_labels[0])\n","plt.show()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["torch.Size([60000, 28, 28])\n","torch.Size([60000])\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPoAAAEHCAYAAACHl1tOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBV0kAgq6SAQUdJEI/D/i+FBMU4lO7gAAAABJRU5ErkJggg==\n","text/plain":["<matplotlib.figure.Figure at 0x7fef33fcfd68>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"kSPcSUAFJO3v","colab_type":"text"},"cell_type":"markdown","source":["#Implementacao\n","\n","## Modelo"]},{"metadata":{"id":"WS0Chma_JQdw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Sequential(         # input shape (1, 28, 28)\n","            nn.Conv2d(\n","                in_channels=1,              # input height\n","                out_channels=16,            # n_filters\n","                kernel_size=5,              # filter size\n","                stride=1,                   # filter movement/step\n","                padding=2,                  # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n","            ),                              # output shape (16, 28, 28)\n","            nn.ReLU(),                      # activation\n","            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 14, 14)\n","        )\n","        self.conv2 = nn.Sequential(         # input shape (1, 28, 28)\n","            nn.Conv2d(16, 32, 5, 1, 2),     # output shape (32, 14, 14)\n","            nn.ReLU(),                      # activation\n","            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n","        )\n","        self.out = nn.Linear(32 * 7 * 7, 10)   # fully connected layer, output 10 classes\n","\n","        \n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = x.view(x.size(0), -1)           # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n","        output = self.out(x)\n","        return output, x                    # return x for visualization"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q9De6NyVJzEW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":238},"outputId":"89763451-9ef1-4e20-9512-4b7a218821e7","executionInfo":{"status":"ok","timestamp":1532122236606,"user_tz":-570,"elapsed":2367,"user":{"displayName":"Rafa Félix","photoUrl":"//lh4.googleusercontent.com/-rJxKyqW78NY/AAAAAAAAAAI/AAAAAAAAAIA/T-S-BEUsMmc/s50-c-k-no/photo.jpg","userId":"108986600904287319000"}}},"cell_type":"code","source":["net = CNN()\n","\n","print(net)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["CNN(\n","  (conv1): Sequential(\n","    (0): Conv2d (1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n","  )\n","  (conv2): Sequential(\n","    (0): Conv2d (16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n","  )\n","  (out): Linear(in_features=1568, out_features=10)\n",")\n"],"name":"stdout"}]},{"metadata":{"id":"iDZ8IoFCJsal","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["if use_cuda and torch.cuda.is_available():\n","    net.cuda()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TuFeti1HKnM_","colab_type":"text"},"cell_type":"markdown","source":["## Optimizer e Funcao Objetivo"]},{"metadata":{"id":"Ray9nIzuZdHh","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bqS7ntyvKygm","colab_type":"text"},"cell_type":"markdown","source":["# Treinando a Rede"]},{"metadata":{"id":"UzTmPHnMKxke","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":697},"outputId":"9d20f95d-a82b-46fa-b421-33d5a723b619","executionInfo":{"status":"ok","timestamp":1532122308037,"user_tz":-570,"elapsed":48260,"user":{"displayName":"Rafa Félix","photoUrl":"//lh4.googleusercontent.com/-rJxKyqW78NY/AAAAAAAAAAI/AAAAAAAAAIA/T-S-BEUsMmc/s50-c-k-no/photo.jpg","userId":"108986600904287319000"}}},"cell_type":"code","source":["for epoch in range(num_epochs):\n","    start = time.time()\n","\n","    for i, (images, labels) in enumerate(train_loader):   # Load a batch of images with its (index, data, class)\n","        \n","        #images = Variable(images.view(-1, 28*28))         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n","        images = Variable(images)\n","        labels = Variable(labels)\n","        \n","        if use_cuda and torch.cuda.is_available():\n","            images = images.cuda()\n","            labels = labels.cuda()\n","        \n","        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n","        outputs = net(images) [0]                          # Forward pass: compute the output class given a image\n","        loss = criterion(outputs, labels)                 # Compute the loss: difference between the output class and the pre-given label\n","        loss.backward()                                   # Backward pass: compute the weight\n","        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n","        \n","        if (i+1) % 100 == 0:                              # Logging\n","            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n","                 %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n","    runtime = time.time() -  start\n","    print(\"Resumo da epoch [%d/%d] runtime: %.4f\"%(epoch+1, num_epochs, runtime))\n","    print(\"-\"*70)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Epoch [1/5], Step [100/600], Loss: 0.2889\n","Epoch [1/5], Step [200/600], Loss: 0.0968\n","Epoch [1/5], Step [300/600], Loss: 0.1249\n","Epoch [1/5], Step [400/600], Loss: 0.1027\n","Epoch [1/5], Step [500/600], Loss: 0.0674\n","Epoch [1/5], Step [600/600], Loss: 0.1202\n","Resumo da epoch [1/5] runtime: 10.6538\n","----------------------------------------------------------------------\n","Epoch [2/5], Step [100/600], Loss: 0.0344\n","Epoch [2/5], Step [200/600], Loss: 0.0534\n","Epoch [2/5], Step [300/600], Loss: 0.0204\n","Epoch [2/5], Step [400/600], Loss: 0.1273\n","Epoch [2/5], Step [500/600], Loss: 0.1240\n","Epoch [2/5], Step [600/600], Loss: 0.0660\n","Resumo da epoch [2/5] runtime: 8.2841\n","----------------------------------------------------------------------\n","Epoch [3/5], Step [100/600], Loss: 0.0499\n","Epoch [3/5], Step [200/600], Loss: 0.0110\n","Epoch [3/5], Step [300/600], Loss: 0.0301\n","Epoch [3/5], Step [400/600], Loss: 0.0756\n","Epoch [3/5], Step [500/600], Loss: 0.0421\n","Epoch [3/5], Step [600/600], Loss: 0.0561\n","Resumo da epoch [3/5] runtime: 8.6187\n","----------------------------------------------------------------------\n","Epoch [4/5], Step [100/600], Loss: 0.0283\n","Epoch [4/5], Step [200/600], Loss: 0.1730\n","Epoch [4/5], Step [300/600], Loss: 0.0060\n","Epoch [4/5], Step [400/600], Loss: 0.0421\n","Epoch [4/5], Step [500/600], Loss: 0.0058\n","Epoch [4/5], Step [600/600], Loss: 0.0305\n","Resumo da epoch [4/5] runtime: 10.3770\n","----------------------------------------------------------------------\n","Epoch [5/5], Step [100/600], Loss: 0.0130\n","Epoch [5/5], Step [200/600], Loss: 0.0334\n","Epoch [5/5], Step [300/600], Loss: 0.0191\n","Epoch [5/5], Step [400/600], Loss: 0.0893\n","Epoch [5/5], Step [500/600], Loss: 0.0118\n","Epoch [5/5], Step [600/600], Loss: 0.0461\n","Resumo da epoch [5/5] runtime: 8.8807\n","----------------------------------------------------------------------\n"],"name":"stdout"}]},{"metadata":{"id":"0mmNrXIRe9Ff","colab_type":"text"},"cell_type":"markdown","source":["## Testando a Neural Network\n"]},{"metadata":{"id":"z8cedCvVbBgf","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"61bfb7e9-8ce6-4dee-ca85-d1bfc92093f6","executionInfo":{"status":"ok","timestamp":1532122378805,"user_tz":-570,"elapsed":2766,"user":{"displayName":"Rafa Félix","photoUrl":"//lh4.googleusercontent.com/-rJxKyqW78NY/AAAAAAAAAAI/AAAAAAAAAIA/T-S-BEUsMmc/s50-c-k-no/photo.jpg","userId":"108986600904287319000"}}},"cell_type":"code","source":["correct = 0\n","total = 0\n","for images, labels in test_loader:\n","    #images = Variable(images.view(-1, 28*28))\n","    images = Variable(images)\n","    \n","    if use_cuda and torch.cuda.is_available():\n","        images = images.cuda()\n","        labels = labels.cuda()\n","    \n","    \n","    outputs = net(images)[0]\n","    _, predicted = torch.max(outputs.data, 1)  # Choose the best class from the output: The class with the best score\n","    total += labels.size(0)                    # Increment the total count\n","    correct += (predicted == labels).sum()     # Increment the correct count\n","    \n","print('Accuracy of the network on the 10K test images: %d %%' % (100 * correct / total))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Accuracy of the network on the 10K test images: 98 %\n"],"name":"stdout"}]}]}